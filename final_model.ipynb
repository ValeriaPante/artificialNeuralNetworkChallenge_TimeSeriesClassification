{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oDqq8gZW4Sw",
        "outputId": "36c3e739-048e-43ad-cf3a-a07c08b13ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOp3b5CWW_7g",
        "outputId": "f260c391-70ea-4199-8a60-4b290718739c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ANN_Challenge2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/ANN_Challenge2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9lHGBJ3XHDX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd \n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZC_yloGXnYy",
        "outputId": "ca2693df-7b0d-427a-f5e8-b66f2aa0797c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open training_dataset_homework2.zip, training_dataset_homework2.zip.zip or training_dataset_homework2.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip training_dataset_homework2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUPc-Ps5XoGP"
      },
      "outputs": [],
      "source": [
        "# import dataset\n",
        "X_train = np.load('/content/drive/My Drive/ANN_Challenge2/training_dataset_homework2/x_train.npy')\n",
        "y_train = np.load('/content/drive/My Drive/ANN_Challenge2/training_dataset_homework2/y_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect data shape\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCD8m9Il4I3t",
        "outputId": "ea8030ca-2d5a-4093-9488-e057ab922bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2429, 36, 6), (2429,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set input shape of a sample\n",
        "input_shape = X_train.shape[1:]"
      ],
      "metadata": {
        "id": "gSM3gaqEigDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect class distribution\n",
        "labels = {\n",
        "    0: 'Wish',\n",
        "    1: 'Another',\n",
        "    2: 'Comfortably',\n",
        "    3: 'Money',\n",
        "    4: 'Breathe',\n",
        "    5: 'Time',\n",
        "    6: 'Brain',\n",
        "    7: 'Echoes',\n",
        "    8: 'Wearing',\n",
        "    9: 'Sorrow',\n",
        "    10: 'Hey',\n",
        "    11: 'Shine',\n",
        "}\n",
        "\n",
        "y = [None]*len(y_train)\n",
        "for i in range(len(y_train)):\n",
        "  y[i] = labels[y_train[i]]\n",
        "\n",
        "plt.figure(figsize=(17,5))\n",
        "sns.countplot(y)\n",
        "plt.title('Count of samples per class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4QPo1RwLhZDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbT35V-OdbNP",
        "outputId": "f73bbf0a-4843-4aff-e9fa-91a70d979d89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2429, 36, 6), (2429, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Convert the sparse labels to categorical values\n",
        "y_train = tfk.utils.to_categorical(y_train)\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEeItZqH74TE"
      },
      "outputs": [],
      "source": [
        "# shuffle data\n",
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWX3OI3Gd0AE"
      },
      "outputs": [],
      "source": [
        "# set hyperparameters for training\n",
        "classes = 12\n",
        "batch_size = 64\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhQ41hyYNb1j"
      },
      "outputs": [],
      "source": [
        "# defines a custome scaler to be applied before the actual model, both at training and prediction time\n",
        "class CustomScalerLayer(tfkl.Layer):\n",
        "  def __init__(self, mean, std):\n",
        "    super(CustomScalerLayer, self).__init__()\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "  def call(self, inputs):\n",
        "    return (inputs - self.mean)/self.std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbExhwfyQ3hf"
      },
      "outputs": [],
      "source": [
        "# compute mean and std per feature\n",
        "data_mean = np.empty(shape=6)\n",
        "data_std = np.empty(shape=6)\n",
        "\n",
        "for i in range(6):\n",
        "  data_mean[i] = X_train[:,:,i].mean()\n",
        "  data_std[i] = X_train[:,:,i].std()\n",
        "\n",
        "data_mean, data_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMr-pZTnVRIc"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, classes, mean, std):\n",
        "    input_layer = tfkl.Input(input_shape)\n",
        "\n",
        "    # standard scale input\n",
        "    scaler = CustomScalerLayer(mean,std)(input_layer)\n",
        "\n",
        "    # BLOCK 1 of convulutions\n",
        "    conv1 = tfkl.Conv1D(64, 8, padding='same')(scaler)\n",
        "    conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv1D(64, 5, padding='same')(conv1)\n",
        "    conv2 = tfkl.Activation('relu')(conv2)\n",
        "    \n",
        "    conv3 = tfkl.Conv1D(64, 3, padding='same')(conv2)\n",
        "\n",
        "    # expand channels for the sum\n",
        "    shortcut = tfkl.Conv1D(filters=64, kernel_size=1, padding='same')(scaler)\n",
        "    shortcut = tfkl.BatchNormalization()(shortcut)\n",
        "\n",
        "    # sum to create the skip connection\n",
        "    output_layer_block_1 = tfkl.add([shortcut, conv3])\n",
        "    output_layer_block_1 = tfkl.Activation('relu')(output_layer_block_1)\n",
        "\n",
        "    # BLOCK 2 of convulutions\n",
        "    conv1 = tfkl.Conv1D(128, 8, padding='same')(output_layer_block_1)\n",
        "    conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv1D(128, 5, padding='same')(conv1)\n",
        "    conv2 = tfkl.Activation('relu')(conv2)\n",
        "    \n",
        "    conv3 = tfkl.Conv1D(128, 3, padding='same')(conv2)\n",
        "\n",
        "    # expand channels for the sum\n",
        "    shortcut = tfkl.Conv1D(filters=128, kernel_size=1, padding='same')(output_layer_block_1)\n",
        "    shortcut = tfkl.BatchNormalization()(shortcut)\n",
        "\n",
        "    # sum to create the skip connection\n",
        "    output_layer_block_2 = tfkl.add([shortcut, conv3])\n",
        "    output_layer_block_2 = tfkl.Activation('relu')(output_layer_block_2)\n",
        "\n",
        "    # BLOCK 3  of convulutions\n",
        "    conv1 = tfkl.Conv1D(128, 8, padding='same')(output_layer_block_2)\n",
        "    conv1 = tfkl.Activation('relu')(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv1D(128, 5, padding='same')(conv1)\n",
        "    conv2 = tfkl.Activation('relu')(conv2)\n",
        "    \n",
        "    conv3 = tfkl.Conv1D(128, 3, padding='same')(conv2)\n",
        "\n",
        "    # no need to expand channels because they are equal\n",
        "    shortcut = tfkl.BatchNormalization()(output_layer_block_2)\n",
        "\n",
        "    # sum to create the skip connection\n",
        "    output_layer_block_3 = tfkl.add([shortcut, conv3])\n",
        "    output_layer_block_3 = tfkl.Activation('relu')(output_layer_block_3)\n",
        "\n",
        "    # FINAL\n",
        "\n",
        "    # expand channels to match the size of the output of the last block\n",
        "    shortcut = tfkl.Conv1D(filters=128, kernel_size=1, padding='same')(scaler)\n",
        "\n",
        "    # compute attention between input and output of the last block\n",
        "    attention = tfkl.MultiHeadAttention(10,32)(shortcut, output_layer_block_3)\n",
        "\n",
        "    gap_layer = tfkl.GlobalAveragePooling1D()(attention)\n",
        "    \n",
        "    output_layer = tfkl.Dense(classes, activation='softmax')(gap_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUFembPYVX1_"
      },
      "outputs": [],
      "source": [
        "# build model\n",
        "model = build_model(input_shape, classes, data_mean, data_std)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phOS015tVaQg"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = batch_size, \n",
        "    epochs = epochs,\n",
        "    validation_split=.2,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=100, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.5, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('SubmissionModel')"
      ],
      "metadata": {
        "id": "sThPUfzoOpnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3c65b8-a566-44b0-b1bf-576f06855046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}